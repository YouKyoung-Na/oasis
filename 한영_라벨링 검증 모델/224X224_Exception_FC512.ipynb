{"cells":[{"cell_type":"markdown","metadata":{"id":"OOdkIMs6RGnB"},"source":["# Kaggle ML - CBHY #\n"]},{"cell_type":"markdown","metadata":{"id":"tX8Ou8aVRbyZ"},"source":["## Weather Datasets ##"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4oqVX02BOTl5"},"outputs":[],"source":["# import Lib for DeepLearning\n","import numpy as np\n","import pandas as pd\n","import sklearn\n","import tensorflow as tf\n","import cv2\n","import matplotlib.pyplot as plt\n","import folium\n","import os\n","import sys\n","\n","\n","# import CodeByHY as CBHY\n","\n","\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, GlobalMaxPooling2D\n","from tensorflow.keras.layers import Dropout, LSTM, Flatten\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Transfer Learning Model in ImageNet\n","from tensorflow.keras.applications import VGG16, Xception\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28972,"status":"ok","timestamp":1654573998878,"user":{"displayName":"CBHY","userId":"04315949426211558474"},"user_tz":-540},"id":"USpx0sNjUEdk","outputId":"aa982a9b-5e73-4a55-8ae6-a11c096e7bd1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hsal6lyiUR3U"},"outputs":[],"source":["train_df = pd.read_csv(\"/content/drive/MyDrive/mljnu/cnu-mlclass2/train.csv\")"]},{"cell_type":"markdown","metadata":{"id":"XZVvwxYEUmcg"},"source":["### Train DataFrame 분포 ###"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1654574001201,"user":{"displayName":"CBHY","userId":"04315949426211558474"},"user_tz":-540},"id":"zCZKThaHUjuw","outputId":"931ec775-93e3-4a50-add1-a0e2c000cc39"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["           image  label\n","0   rain_418.jpg   rain\n","1   snow_150.jpg   snow\n","2  sunny_809.jpg  sunny\n","3    fog_750.jpg    fog\n","4   dust_646.jpg   dust"],"text/html":["\n","  <div id=\"df-1c2fafaa-16b7-44fd-ae11-aeb8af6aef60\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>rain_418.jpg</td>\n","      <td>rain</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>snow_150.jpg</td>\n","      <td>snow</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sunny_809.jpg</td>\n","      <td>sunny</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>fog_750.jpg</td>\n","      <td>fog</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>dust_646.jpg</td>\n","      <td>dust</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c2fafaa-16b7-44fd-ae11-aeb8af6aef60')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1c2fafaa-16b7-44fd-ae11-aeb8af6aef60 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1c2fafaa-16b7-44fd-ae11-aeb8af6aef60');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}],"source":["train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1654574001202,"user":{"displayName":"CBHY","userId":"04315949426211558474"},"user_tz":-540},"id":"5I22jsfxUxtf","outputId":"419ed43a-1f9d-438b-c8e6-23c45bc66334"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 4355 entries, 0 to 4354\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   image   4355 non-null   object\n"," 1   label   4355 non-null   object\n","dtypes: object(2)\n","memory usage: 68.2+ KB\n"]}],"source":["train_df.info()"]},{"cell_type":"markdown","metadata":{"id":"w_hRSFf3U4wP"},"source":["column 2개, 결측치 없음, Dtype 모두 object  \n","  \n","image = 사진 파일 이름  \n","label = 날씨(정답값)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1654574001203,"user":{"displayName":"CBHY","userId":"04315949426211558474"},"user_tz":-540},"id":"HksjdMPBVKfL","outputId":"745ee824-69dd-441c-fabe-a1c2c53d2e7e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["sunny    1071\n","rain      857\n","snow      857\n","dust      820\n","fog       750\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":6}],"source":["train_df.label.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"29I0VGdOfbGJ"},"outputs":[],"source":["\n","TRAINING_DIR = \"/content/drive/MyDrive/mljnu/cnu-mlclass2/train\"\n","\n","training_datagen = ImageDataGenerator(\n","    rescale=1. / 255, # Normalization\n","    rotation_range=40, \n","    width_shift_range=0.35,\n","    height_shift_range=0.35,\n","    shear_range=0.3,\n","    zoom_range=0.3,\n","    horizontal_flip=True,\n","        fill_mode='nearest', \n","    validation_split=0.06,\n","    )\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4861,"status":"ok","timestamp":1654574006055,"user":{"displayName":"CBHY","userId":"04315949426211558474"},"user_tz":-540},"id":"-l-SJnOxfbDZ","outputId":"cc9352f3-ef0a-477b-9b25-127f0ead932b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 4095 images belonging to 5 classes.\n","Found 260 images belonging to 5 classes.\n"]}],"source":["# IDG 적용 \n","training_generator = training_datagen.flow_from_directory(TRAINING_DIR, # root 폴더 경로\n","                                                          batch_size=32, \n","                                                          target_size=(224, 224), \n","                                                          class_mode='categorical', # 다중 분류\n","                                                          subset='training',\n","                                                         )\n","\n","validation_generator = training_datagen.flow_from_directory(TRAINING_DIR, \n","                                                          batch_size=32, \n","                                                          target_size=(224, 224), \n","                                                          class_mode='categorical',\n","                                                          subset='validation', \n","                                                         )"]},{"cell_type":"markdown","metadata":{"id":"iZyTyfn6mv_S"},"source":["1. flow_from_driectory 사용,  \n","BastLine Code에서 flow_from_dataframe 사용  \n","굳이 DataFrame으로 받은 이유를 잘 모르겠음\n","  \n","   \n","2. 굳이 Split단계에서 sklearn.model_selection.train_test_split 사용한 이유 잘 모르겠음"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7044,"status":"ok","timestamp":1654574013088,"user":{"displayName":"CBHY","userId":"04315949426211558474"},"user_tz":-540},"id":"CBZL1vWkfa7x","outputId":"f4d0f52f-6f8e-4e9f-d9fe-73b2faaaf1c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","83689472/83683744 [==============================] - 1s 0us/step\n","83697664/83683744 [==============================] - 1s 0us/step\n"]}],"source":["transfer_model = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","transfer_model.trainable=True\n","\n","model = Sequential([\n","    transfer_model,\n","    Flatten(),\n","    Dropout(0.5),\n","    Dense(1024, activation='relu'),\n","    Dense(512, activation='relu'),\n","    Dense(512, activation='relu'),\n","    Dense(256, activation='relu'), \n","    Dense(256, activation='relu'), \n","    Dense(128, activation='relu'), \n","    Dense(64, activation='relu'), \n","    Dense(64, activation='relu'),\n","    Dense(32, activation='relu'),\n","    Dense(32, activation='relu'), \n","    Dense(5, activation='softmax'),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1654574013090,"user":{"displayName":"CBHY","userId":"04315949426211558474"},"user_tz":-540},"id":"OhZ7POvCW9-C","outputId":"97658e0f-eff1-40a6-8722-27c455e3612b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," xception (Functional)       (None, 7, 7, 2048)        20861480  \n","                                                                 \n"," flatten (Flatten)           (None, 100352)            0         \n","                                                                 \n"," dropout (Dropout)           (None, 100352)            0         \n","                                                                 \n"," dense (Dense)               (None, 1024)              102761472 \n","                                                                 \n"," dense_1 (Dense)             (None, 512)               524800    \n","                                                                 \n"," dense_2 (Dense)             (None, 512)               262656    \n","                                                                 \n"," dense_3 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_4 (Dense)             (None, 256)               65792     \n","                                                                 \n"," dense_5 (Dense)             (None, 128)               32896     \n","                                                                 \n"," dense_6 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dense_7 (Dense)             (None, 64)                4160      \n","                                                                 \n"," dense_8 (Dense)             (None, 32)                2080      \n","                                                                 \n"," dense_9 (Dense)             (None, 32)                1056      \n","                                                                 \n"," dense_10 (Dense)            (None, 5)                 165       \n","                                                                 \n","=================================================================\n","Total params: 124,656,141\n","Trainable params: 124,601,613\n","Non-trainable params: 54,528\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wkAcbvpJpS48"},"outputs":[],"source":["checkpoint_path = \"my_checkpoint1.ckpt\" # 체크포인트 위치는 로컬, 이름.ckpt or 이름.m5\n","checkpoint = ModelCheckpoint(filepath=checkpoint_path, \n","                             save_weights_only=True, # 가중치만 저장\n","                             save_best_only=True, # 가장 좋은 결과만 저장\n","                             monitor='val_loss',  # 기준 = 'validation_loss가 가장 낮은 것'\n","                             verbose=1) # 출력"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JNdODH2bolaL"},"outputs":[],"source":["from tensorflow.keras.optimizers import Adam\n","\n","tuned_Adam = Adam(learning_rate = 0.00035)\n","\n","\n","model.compile(optimizer = tuned_Adam, loss=\"categorical_crossentropy\", metrics=['ACC'])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_CUukwh0onJG","outputId":"0a3dd349-26fb-4492-89d7-c23f5421df7f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","128/128 [==============================] - ETA: 0s - loss: 0.9374 - ACC: 0.6491 \n","Epoch 1: val_loss improved from inf to 0.52922, saving model to my_checkpoint1.ckpt\n","128/128 [==============================] - 1891s 15s/step - loss: 0.9374 - ACC: 0.6491 - val_loss: 0.5292 - val_ACC: 0.8885\n","Epoch 2/100\n","128/128 [==============================] - ETA: 0s - loss: 0.4011 - ACC: 0.8894\n","Epoch 2: val_loss improved from 0.52922 to 0.44648, saving model to my_checkpoint1.ckpt\n","128/128 [==============================] - 91s 705ms/step - loss: 0.4011 - ACC: 0.8894 - val_loss: 0.4465 - val_ACC: 0.8654\n","Epoch 3/100\n","128/128 [==============================] - ETA: 0s - loss: 0.3309 - ACC: 0.9101\n","Epoch 3: val_loss improved from 0.44648 to 0.40235, saving model to my_checkpoint1.ckpt\n","128/128 [==============================] - 90s 702ms/step - loss: 0.3309 - ACC: 0.9101 - val_loss: 0.4023 - val_ACC: 0.8885\n","Epoch 4/100\n","128/128 [==============================] - ETA: 0s - loss: 0.2671 - ACC: 0.9319\n","Epoch 4: val_loss improved from 0.40235 to 0.34912, saving model to my_checkpoint1.ckpt\n","128/128 [==============================] - 92s 715ms/step - loss: 0.2671 - ACC: 0.9319 - val_loss: 0.3491 - val_ACC: 0.9231\n","Epoch 5/100\n","128/128 [==============================] - ETA: 0s - loss: 0.2652 - ACC: 0.9304\n","Epoch 5: val_loss improved from 0.34912 to 0.22872, saving model to my_checkpoint1.ckpt\n","128/128 [==============================] - 90s 703ms/step - loss: 0.2652 - ACC: 0.9304 - val_loss: 0.2287 - val_ACC: 0.9115\n","Epoch 6/100\n","128/128 [==============================] - ETA: 0s - loss: 0.2068 - ACC: 0.9448\n","Epoch 6: val_loss did not improve from 0.22872\n","128/128 [==============================] - 86s 665ms/step - loss: 0.2068 - ACC: 0.9448 - val_loss: 0.2582 - val_ACC: 0.9385\n","Epoch 7/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1890 - ACC: 0.9475\n","Epoch 7: val_loss improved from 0.22872 to 0.19645, saving model to my_checkpoint1.ckpt\n","128/128 [==============================] - 92s 713ms/step - loss: 0.1890 - ACC: 0.9475 - val_loss: 0.1965 - val_ACC: 0.9500\n","Epoch 8/100\n","128/128 [==============================] - ETA: 0s - loss: 0.2587 - ACC: 0.9333\n","Epoch 8: val_loss did not improve from 0.19645\n","128/128 [==============================] - 85s 659ms/step - loss: 0.2587 - ACC: 0.9333 - val_loss: 0.2883 - val_ACC: 0.9269\n","Epoch 9/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1836 - ACC: 0.9524\n","Epoch 9: val_loss did not improve from 0.19645\n","128/128 [==============================] - 86s 665ms/step - loss: 0.1836 - ACC: 0.9524 - val_loss: 0.4090 - val_ACC: 0.9231\n","Epoch 10/100\n","128/128 [==============================] - ETA: 0s - loss: 0.2122 - ACC: 0.9463\n","Epoch 10: val_loss improved from 0.19645 to 0.17567, saving model to my_checkpoint1.ckpt\n","128/128 [==============================] - 90s 701ms/step - loss: 0.2122 - ACC: 0.9463 - val_loss: 0.1757 - val_ACC: 0.9692\n","Epoch 11/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1939 - ACC: 0.9504\n","Epoch 11: val_loss did not improve from 0.17567\n","128/128 [==============================] - 85s 659ms/step - loss: 0.1939 - ACC: 0.9504 - val_loss: 0.3260 - val_ACC: 0.9000\n","Epoch 12/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1442 - ACC: 0.9590\n","Epoch 12: val_loss improved from 0.17567 to 0.15016, saving model to my_checkpoint1.ckpt\n","128/128 [==============================] - 90s 700ms/step - loss: 0.1442 - ACC: 0.9590 - val_loss: 0.1502 - val_ACC: 0.9615\n","Epoch 13/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1542 - ACC: 0.9551\n","Epoch 13: val_loss did not improve from 0.15016\n","128/128 [==============================] - 85s 662ms/step - loss: 0.1542 - ACC: 0.9551 - val_loss: 0.3570 - val_ACC: 0.9038\n","Epoch 14/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1292 - ACC: 0.9639\n","Epoch 14: val_loss did not improve from 0.15016\n","128/128 [==============================] - 85s 659ms/step - loss: 0.1292 - ACC: 0.9639 - val_loss: 0.3164 - val_ACC: 0.9346\n","Epoch 15/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1663 - ACC: 0.9600\n","Epoch 15: val_loss did not improve from 0.15016\n","128/128 [==============================] - 86s 665ms/step - loss: 0.1663 - ACC: 0.9600 - val_loss: 0.2237 - val_ACC: 0.9385\n","Epoch 16/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1463 - ACC: 0.9631\n","Epoch 16: val_loss did not improve from 0.15016\n","128/128 [==============================] - 85s 663ms/step - loss: 0.1463 - ACC: 0.9631 - val_loss: 0.2080 - val_ACC: 0.9385\n","Epoch 17/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1579 - ACC: 0.9621\n","Epoch 17: val_loss did not improve from 0.15016\n","128/128 [==============================] - 85s 664ms/step - loss: 0.1579 - ACC: 0.9621 - val_loss: 0.2590 - val_ACC: 0.9308\n","Epoch 18/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1554 - ACC: 0.9568\n","Epoch 18: val_loss improved from 0.15016 to 0.11794, saving model to my_checkpoint1.ckpt\n","128/128 [==============================] - 92s 713ms/step - loss: 0.1554 - ACC: 0.9568 - val_loss: 0.1179 - val_ACC: 0.9615\n","Epoch 19/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1294 - ACC: 0.9665\n","Epoch 19: val_loss did not improve from 0.11794\n","128/128 [==============================] - 86s 664ms/step - loss: 0.1294 - ACC: 0.9665 - val_loss: 0.1786 - val_ACC: 0.9538\n","Epoch 20/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1102 - ACC: 0.9714\n","Epoch 20: val_loss did not improve from 0.11794\n","128/128 [==============================] - 85s 659ms/step - loss: 0.1102 - ACC: 0.9714 - val_loss: 0.1598 - val_ACC: 0.9615\n","Epoch 21/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1086 - ACC: 0.9726\n","Epoch 21: val_loss did not improve from 0.11794\n","128/128 [==============================] - 85s 661ms/step - loss: 0.1086 - ACC: 0.9726 - val_loss: 0.1698 - val_ACC: 0.9423\n","Epoch 22/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1084 - ACC: 0.9709\n","Epoch 22: val_loss did not improve from 0.11794\n","128/128 [==============================] - 85s 660ms/step - loss: 0.1084 - ACC: 0.9709 - val_loss: 0.2712 - val_ACC: 0.9269\n","Epoch 23/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1098 - ACC: 0.9731\n","Epoch 23: val_loss did not improve from 0.11794\n","128/128 [==============================] - 85s 664ms/step - loss: 0.1098 - ACC: 0.9731 - val_loss: 0.2378 - val_ACC: 0.9577\n","Epoch 24/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1349 - ACC: 0.9643\n","Epoch 24: val_loss did not improve from 0.11794\n","128/128 [==============================] - 85s 661ms/step - loss: 0.1349 - ACC: 0.9643 - val_loss: 0.2580 - val_ACC: 0.9231\n","Epoch 25/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1151 - ACC: 0.9700\n","Epoch 25: val_loss did not improve from 0.11794\n","128/128 [==============================] - 85s 661ms/step - loss: 0.1151 - ACC: 0.9700 - val_loss: 0.1810 - val_ACC: 0.9462\n","Epoch 26/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1113 - ACC: 0.9707\n","Epoch 26: val_loss did not improve from 0.11794\n","128/128 [==============================] - 85s 657ms/step - loss: 0.1113 - ACC: 0.9707 - val_loss: 0.1902 - val_ACC: 0.9385\n","Epoch 27/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1141 - ACC: 0.9719\n","Epoch 27: val_loss did not improve from 0.11794\n","128/128 [==============================] - 85s 661ms/step - loss: 0.1141 - ACC: 0.9719 - val_loss: 0.3556 - val_ACC: 0.9192\n","Epoch 28/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1322 - ACC: 0.9641\n","Epoch 28: val_loss did not improve from 0.11794\n","128/128 [==============================] - 85s 661ms/step - loss: 0.1322 - ACC: 0.9641 - val_loss: 0.1852 - val_ACC: 0.9538\n","Epoch 29/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1192 - ACC: 0.9683\n","Epoch 29: val_loss did not improve from 0.11794\n","128/128 [==============================] - 85s 663ms/step - loss: 0.1192 - ACC: 0.9683 - val_loss: 0.1743 - val_ACC: 0.9577\n","Epoch 30/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1266 - ACC: 0.9665\n","Epoch 30: val_loss did not improve from 0.11794\n","128/128 [==============================] - 85s 660ms/step - loss: 0.1266 - ACC: 0.9665 - val_loss: 0.2599 - val_ACC: 0.9346\n","Epoch 31/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0790 - ACC: 0.9783\n","Epoch 31: val_loss did not improve from 0.11794\n","128/128 [==============================] - 85s 663ms/step - loss: 0.0790 - ACC: 0.9783 - val_loss: 0.1741 - val_ACC: 0.9615\n","Epoch 32/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0987 - ACC: 0.9729\n","Epoch 32: val_loss did not improve from 0.11794\n","128/128 [==============================] - 85s 662ms/step - loss: 0.0987 - ACC: 0.9729 - val_loss: 0.2741 - val_ACC: 0.9192\n","Epoch 33/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0945 - ACC: 0.9726\n","Epoch 33: val_loss did not improve from 0.11794\n","128/128 [==============================] - 85s 663ms/step - loss: 0.0945 - ACC: 0.9726 - val_loss: 0.1233 - val_ACC: 0.9462\n","Epoch 34/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1151 - ACC: 0.9678\n","Epoch 34: val_loss did not improve from 0.11794\n","128/128 [==============================] - 86s 667ms/step - loss: 0.1151 - ACC: 0.9678 - val_loss: 0.1445 - val_ACC: 0.9423\n","Epoch 35/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1081 - ACC: 0.9726\n","Epoch 35: val_loss did not improve from 0.11794\n","128/128 [==============================] - 85s 660ms/step - loss: 0.1081 - ACC: 0.9726 - val_loss: 0.1425 - val_ACC: 0.9500\n","Epoch 36/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0927 - ACC: 0.9773\n","Epoch 36: val_loss did not improve from 0.11794\n","128/128 [==============================] - 85s 661ms/step - loss: 0.0927 - ACC: 0.9773 - val_loss: 0.2985 - val_ACC: 0.9538\n","Epoch 37/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1114 - ACC: 0.9702\n","Epoch 37: val_loss did not improve from 0.11794\n","128/128 [==============================] - 85s 660ms/step - loss: 0.1114 - ACC: 0.9702 - val_loss: 0.2038 - val_ACC: 0.9577\n","Epoch 38/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0789 - ACC: 0.9812\n","Epoch 38: val_loss did not improve from 0.11794\n","128/128 [==============================] - 85s 659ms/step - loss: 0.0789 - ACC: 0.9812 - val_loss: 0.1370 - val_ACC: 0.9615\n","Epoch 39/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0829 - ACC: 0.9790\n","Epoch 39: val_loss did not improve from 0.11794\n","128/128 [==============================] - 85s 660ms/step - loss: 0.0829 - ACC: 0.9790 - val_loss: 0.3205 - val_ACC: 0.9038\n","Epoch 40/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1310 - ACC: 0.9678\n","Epoch 40: val_loss did not improve from 0.11794\n","128/128 [==============================] - 85s 661ms/step - loss: 0.1310 - ACC: 0.9678 - val_loss: 0.1751 - val_ACC: 0.9538\n","Epoch 41/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0793 - ACC: 0.9795\n","Epoch 41: val_loss did not improve from 0.11794\n","128/128 [==============================] - 85s 659ms/step - loss: 0.0793 - ACC: 0.9795 - val_loss: 0.1442 - val_ACC: 0.9577\n","Epoch 42/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0768 - ACC: 0.9810\n","Epoch 42: val_loss did not improve from 0.11794\n","128/128 [==============================] - 85s 661ms/step - loss: 0.0768 - ACC: 0.9810 - val_loss: 0.4877 - val_ACC: 0.8923\n","Epoch 43/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0473 - ACC: 0.9866\n","Epoch 43: val_loss did not improve from 0.11794\n","128/128 [==============================] - 85s 662ms/step - loss: 0.0473 - ACC: 0.9866 - val_loss: 0.2761 - val_ACC: 0.9538\n","Epoch 44/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0994 - ACC: 0.9751\n","Epoch 44: val_loss improved from 0.11794 to 0.08070, saving model to my_checkpoint1.ckpt\n","128/128 [==============================] - 90s 698ms/step - loss: 0.0994 - ACC: 0.9751 - val_loss: 0.0807 - val_ACC: 0.9731\n","Epoch 45/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0854 - ACC: 0.9790\n","Epoch 45: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 661ms/step - loss: 0.0854 - ACC: 0.9790 - val_loss: 0.2014 - val_ACC: 0.9500\n","Epoch 46/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1025 - ACC: 0.9731\n","Epoch 46: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 662ms/step - loss: 0.1025 - ACC: 0.9731 - val_loss: 0.2106 - val_ACC: 0.9423\n","Epoch 47/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0619 - ACC: 0.9851\n","Epoch 47: val_loss did not improve from 0.08070\n","128/128 [==============================] - 86s 665ms/step - loss: 0.0619 - ACC: 0.9851 - val_loss: 0.1460 - val_ACC: 0.9538\n","Epoch 48/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0629 - ACC: 0.9834\n","Epoch 48: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 662ms/step - loss: 0.0629 - ACC: 0.9834 - val_loss: 0.3197 - val_ACC: 0.9346\n","Epoch 49/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0760 - ACC: 0.9807\n","Epoch 49: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 663ms/step - loss: 0.0760 - ACC: 0.9807 - val_loss: 0.3693 - val_ACC: 0.9154\n","Epoch 50/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0897 - ACC: 0.9758\n","Epoch 50: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 659ms/step - loss: 0.0897 - ACC: 0.9758 - val_loss: 0.1719 - val_ACC: 0.9654\n","Epoch 51/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0699 - ACC: 0.9812\n","Epoch 51: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 662ms/step - loss: 0.0699 - ACC: 0.9812 - val_loss: 0.1064 - val_ACC: 0.9692\n","Epoch 52/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0840 - ACC: 0.9763\n","Epoch 52: val_loss did not improve from 0.08070\n","128/128 [==============================] - 84s 656ms/step - loss: 0.0840 - ACC: 0.9763 - val_loss: 0.2487 - val_ACC: 0.9423\n","Epoch 53/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1012 - ACC: 0.9785\n","Epoch 53: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 658ms/step - loss: 0.1012 - ACC: 0.9785 - val_loss: 0.2078 - val_ACC: 0.9308\n","Epoch 54/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0763 - ACC: 0.9802\n","Epoch 54: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 659ms/step - loss: 0.0763 - ACC: 0.9802 - val_loss: 0.1940 - val_ACC: 0.9462\n","Epoch 55/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0772 - ACC: 0.9802\n","Epoch 55: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 660ms/step - loss: 0.0772 - ACC: 0.9802 - val_loss: 0.1203 - val_ACC: 0.9500\n","Epoch 56/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0785 - ACC: 0.9817\n","Epoch 56: val_loss did not improve from 0.08070\n","128/128 [==============================] - 86s 666ms/step - loss: 0.0785 - ACC: 0.9817 - val_loss: 0.2034 - val_ACC: 0.9462\n","Epoch 57/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0636 - ACC: 0.9836\n","Epoch 57: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 662ms/step - loss: 0.0636 - ACC: 0.9836 - val_loss: 0.4336 - val_ACC: 0.9346\n","Epoch 58/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0846 - ACC: 0.9797\n","Epoch 58: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 659ms/step - loss: 0.0846 - ACC: 0.9797 - val_loss: 0.1085 - val_ACC: 0.9692\n","Epoch 59/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0440 - ACC: 0.9858\n","Epoch 59: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 664ms/step - loss: 0.0440 - ACC: 0.9858 - val_loss: 0.1331 - val_ACC: 0.9538\n","Epoch 60/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0638 - ACC: 0.9819\n","Epoch 60: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 658ms/step - loss: 0.0638 - ACC: 0.9819 - val_loss: 0.3575 - val_ACC: 0.9077\n","Epoch 61/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0656 - ACC: 0.9849\n","Epoch 61: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 660ms/step - loss: 0.0656 - ACC: 0.9849 - val_loss: 0.1142 - val_ACC: 0.9731\n","Epoch 62/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0690 - ACC: 0.9849\n","Epoch 62: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 658ms/step - loss: 0.0690 - ACC: 0.9849 - val_loss: 0.2373 - val_ACC: 0.9500\n","Epoch 63/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0600 - ACC: 0.9846\n","Epoch 63: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 660ms/step - loss: 0.0600 - ACC: 0.9846 - val_loss: 0.2022 - val_ACC: 0.9423\n","Epoch 64/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0640 - ACC: 0.9834\n","Epoch 64: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 661ms/step - loss: 0.0640 - ACC: 0.9834 - val_loss: 0.1953 - val_ACC: 0.9423\n","Epoch 65/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0743 - ACC: 0.9810\n","Epoch 65: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 658ms/step - loss: 0.0743 - ACC: 0.9810 - val_loss: 0.1838 - val_ACC: 0.9577\n","Epoch 66/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0508 - ACC: 0.9851\n","Epoch 66: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 661ms/step - loss: 0.0508 - ACC: 0.9851 - val_loss: 0.4212 - val_ACC: 0.9269\n","Epoch 67/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0478 - ACC: 0.9863\n","Epoch 67: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 661ms/step - loss: 0.0478 - ACC: 0.9863 - val_loss: 0.1039 - val_ACC: 0.9692\n","Epoch 68/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0623 - ACC: 0.9841\n","Epoch 68: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 662ms/step - loss: 0.0623 - ACC: 0.9841 - val_loss: 0.2343 - val_ACC: 0.9577\n","Epoch 69/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0618 - ACC: 0.9841\n","Epoch 69: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 664ms/step - loss: 0.0618 - ACC: 0.9841 - val_loss: 0.3248 - val_ACC: 0.9346\n","Epoch 70/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0672 - ACC: 0.9856\n","Epoch 70: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 658ms/step - loss: 0.0672 - ACC: 0.9856 - val_loss: 0.1784 - val_ACC: 0.9538\n","Epoch 71/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0672 - ACC: 0.9863\n","Epoch 71: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 660ms/step - loss: 0.0672 - ACC: 0.9863 - val_loss: 0.5683 - val_ACC: 0.8923\n","Epoch 72/100\n","128/128 [==============================] - ETA: 0s - loss: 0.1206 - ACC: 0.9731\n","Epoch 72: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 665ms/step - loss: 0.1206 - ACC: 0.9731 - val_loss: 0.3365 - val_ACC: 0.9000\n","Epoch 73/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0751 - ACC: 0.9780\n","Epoch 73: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 660ms/step - loss: 0.0751 - ACC: 0.9780 - val_loss: 0.2338 - val_ACC: 0.9577\n","Epoch 74/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0731 - ACC: 0.9817\n","Epoch 74: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 660ms/step - loss: 0.0731 - ACC: 0.9817 - val_loss: 0.1953 - val_ACC: 0.9500\n","Epoch 75/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0506 - ACC: 0.9883\n","Epoch 75: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 657ms/step - loss: 0.0506 - ACC: 0.9883 - val_loss: 0.1252 - val_ACC: 0.9692\n","Epoch 76/100\n","128/128 [==============================] - ETA: 0s - loss: 0.0485 - ACC: 0.9885\n","Epoch 76: val_loss did not improve from 0.08070\n","128/128 [==============================] - 85s 662ms/step - loss: 0.0485 - ACC: 0.9885 - val_loss: 0.1580 - val_ACC: 0.9577\n","Epoch 77/100\n"," 39/128 [========>.....................] - ETA: 56s - loss: 0.0567 - ACC: 0.9872"]}],"source":["history = model.fit(training_generator,  # IDG 적용 data set\n","                    validation_data=(validation_generator), # IDG 적용 data set\n","                    epochs=100, # epoch 230으로 진행 한번 해봐도 될듯\n","                    callbacks=[checkpoint],\n","                    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kNLSGLFyonFp"},"outputs":[],"source":["model.load_weights(checkpoint_path)\n","\n","test_df = pd.read_csv(\"/content/drive/MyDrive/mljnu/cnu-mlclass2/\"+\"/test.csv\")\n","test_df.head(5)\n","batch_size = len(test_df[\"image\"])\n","height, width, channel = 224, 224, 3\n","\n","\n","test_path = \"/content/drive/MyDrive/mljnu/cnu-mlclass2/\" + '/test'\n","\n","test_image = np.zeros((batch_size, height, width, channel))\n","print(test_image.shape)\n","cnt=0\n","for i in range(len(test_df[\"image\"])):\n","    path_img = test_df['image'][i]\n","    img = tf.keras.preprocessing.image.load_img(os.path.join(test_path,path_img), target_size=(height, width))\n","    img_tensor = tf.keras.preprocessing.image.img_to_array(img)\n","    img_tensor = np.array(img_tensor,dtype=\"float32\")\n","\n","    img_tensor /= 255\n","    \n","    img_tensor = np.expand_dims(img_tensor, axis=0)\n","    \n","    test_image[i] = img_tensor\n","\n","predictions = model.predict(test_image)\n","pred2label={}\n","\n","\n","for x in training_generator.class_indices.keys():\n","    pred2label[training_generator.class_indices[x]] = x\n","test_df['label'] = [pred2label[np.argmax(pred)] for pred in predictions]\n","test_df\n","test_df.to_csv('./submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a27DFjhponDb"},"outputs":[],"source":["acc = history.history['ACC']\n","val_acc = history.history['val_ACC']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = history.epoch\n","\n","plt.plot(epochs, acc, 'r', label='Training accuracy')\n","plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n","plt.title('Training and validation accuracy')\n","plt.legend()\n","plt.show()\n","\n","print()\n","print()\n","print()\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'r', label='Training Loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","\n","\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"drBRTvgoonBO"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"deeplearning.ipynb","provenance":[],"authorship_tag":"ABX9TyNsUEIfq/4LSk0ER/LkN2rO"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}